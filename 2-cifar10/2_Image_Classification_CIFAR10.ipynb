{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YepYU3SdSa1-"
   },
   "source": [
    "# Exercise 2 - Image Classification using CIFAR10 dataset\n",
    "\n",
    "In this notebook we will build on the knowledge of model building in Exercise 1 to classify objects. \n",
    "\n",
    "We will follow these steps:\n",
    "1. Explore the dataset (CIFAR10)\n",
    "2. Build a small convnet from scratch\n",
    "3. Evaluate training and validation accuracy\n",
    "4. Score the model against test set and submit result\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62EE4dk9Zw-M"
   },
   "source": [
    "## Download and Explore the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjrw2VMDUJC6"
   },
   "source": [
    "Let's start by downloading our dataset, a .zip of 60,000 PNG pictures of different objects, and extracting it locally.\n",
    "\n",
    "**NOTE:** The images used in this exercise are excerpted from the \"CIFAR-10\" available [here](https://www.cs.toronto.edu/~kriz/cifar.html), which contains 60,000 images in 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvMUL9IKVuP-"
   },
   "source": [
    "The contents of the `.zip` are extracted to the base directory, which contains `train` and `val` and `test` subdirectories for the training, validation and test datasets. The folders have the following structure:\n",
    "\n",
    "```\n",
    "---------------\n",
    "train\n",
    "|- airplane\n",
    "|- automobile\n",
    "|- bird\n",
    "|- cat\n",
    "|- deer\n",
    "|- dog\n",
    "|- frog\n",
    "|- horse\n",
    "|- ship\n",
    "|- truck\n",
    "\n",
    "val\n",
    "|- airplane\n",
    "|- automobile\n",
    "|- bird\n",
    "|- cat\n",
    "|- deer\n",
    "|- dog\n",
    "|- frog\n",
    "|- horse\n",
    "|- ship\n",
    "|- truck\n",
    "\n",
    "test\n",
    "|- test\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "kzEr2gZ05RHX",
    "outputId": "0b9ed8e2-d350-486d-f8fd-f821d16ede75"
   },
   "outputs": [],
   "source": [
    "# Creating two directories - \"data\" and \"data/cifar10\" \n",
    "!mkdir data && mkdir data/cifar10\n",
    "# Downloading the CIFAR dataset\n",
    "!wget -N https://s3-us-west-2.amazonaws.com/ai-camp/cifar10.zip\n",
    "# Unzip the data into the folder \"data/cifar10\"\n",
    "!unzip -qq -n cifar10.zip -d data/cifar10\n",
    "# Switch directory to \"data/cifar10\" and show its content\n",
    "!cd data/cifar10 && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YPMa22yaJA-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = 'data/cifar10'\n",
    "\n",
    "# Directory to our training data\n",
    "train_folder = os.path.join(base_dir, 'train')\n",
    "\n",
    "# Directory to our validation data\n",
    "val_folder = os.path.join(base_dir, 'val')\n",
    "\n",
    "# Directory to our training data\n",
    "test_folder = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVCvH_XXuTlu"
   },
   "source": [
    "Now, let's find out the total number of images we have in each `train`, `val` and `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "SIWrHBu1awaC",
    "outputId": "b66b2e5f-9fd2-4450-90b5-f4e2ae0d142a"
   },
   "outputs": [],
   "source": [
    "# List folders and number of files\n",
    "print(\"Directory, Number of files\")\n",
    "for root, subdirs, files in os.walk(base_dir):\n",
    "    print(root, len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvtQnO4CwLtS"
   },
   "source": [
    "We can see that there are 10 categories/folders in each `train` and `val` folder, whereas in the `test` directory, there is only 1 folder.\n",
    "\n",
    "Now let's take a look at a few images to get a better sense of what the `frog` and `airplane` dataset look like. First, configure the matplot parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z8jsWloowYpL"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPDMLSoUxksu"
   },
   "source": [
    "Now, display a batch of 8 frogs and 8 airplanes pictures. You can rerun the cell to see a new batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "uxtrAyx9wa5i",
    "outputId": "7bae2052-c68c-4b7c-e46a-c829091004e9"
   },
   "outputs": [],
   "source": [
    "## Path to frog and airplan\n",
    "train_frog_dir= \"data/cifar10/train/frog\"\n",
    "train_airplane_dir= \"data/cifar10/train/airplane\"\n",
    "train_frog_fnames = os.listdir(train_frog_dir)\n",
    "train_airplane_fnames = os.listdir(train_airplane_dir)\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols, nrows)\n",
    "\n",
    "pic_index += 8\n",
    "next_frog_pix = [os.path.join(train_frog_dir, fname) \n",
    "                for fname in train_frog_fnames[pic_index-8:pic_index]]\n",
    "next_airplane_pix = [os.path.join(train_airplane_dir, fname) \n",
    "                for fname in train_airplane_fnames[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_frog_pix+next_airplane_pix):\n",
    "    # Set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "    \n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_boVgbVAUcVF"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Let's set up data generators that will read images from our source folders and convert them to float32 tensors. We'll have one generator for each training, validation and test folder.\n",
    "\n",
    "### Batch\n",
    "Our generators will yield batches of `10` images of size `32 x 32` and their labels.\n",
    "\n",
    "### Feature scaling\n",
    "As you may know in our MNIST exercise, data that goes into a neural network should be normalised in a way that is easier to be processed by the network. In our case, we will preprocess our images by normalising the pixels values to be in the 0 to 1 range. This happens by dividing each pixel value by 255 and this process is known as data normalisation or rescaling.\n",
    "\n",
    "### Generator - ImageDataGenerator\n",
    "To rescale the data, we use `keras.preprocessing.image.ImageDataGenerator` class with the `rescale` parameter. This class will also allow us to instantiate generators of augmented image batches (and their labels) via `.flow_from_directory(directory)`. These generators can then be used with the Keras model methods that accept data generators as inputs such as `fit_generator`, `evaluate_generator` and `predict_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "kXpGgyCWSF0u",
    "outputId": "f9e8f045-68bb-4f88-d280-c756f5f5d883"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Batch size\n",
    "bs = 10\n",
    "\n",
    "# All images will be resized to this value\n",
    "image_size = (32, 32)\n",
    "\n",
    "# All images will be rescaled by 1./255 \n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./_____)\n",
    "\n",
    "# Flow training images in batches of 10 using train_datagen generator\n",
    "print(\"Preparing generator for train dataset\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory= train_folder, # This is the source directory for training images \n",
    "    target_size=image_size, # All images will be resized to value set in image_size\n",
    "    batch_size=bs,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Flow validation images in batches of 10 using val_datagen generator\n",
    "print(\"Preparing generator for validation dataset\")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory= val_folder, \n",
    "    target_size=image_size,\n",
    "    batch_size=bs,\n",
    "    class_mode='_____')\n",
    "\n",
    "# Flow test images in batches of 10 using test_datagen generator\n",
    "# Added shuffle=False to keep data in same order as labels\n",
    "print(\"Preparing generator for test dataset\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_folder,\n",
    "    target_size=image_size,\n",
    "    batch_size=bs,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "suFcRHxkZIVr"
   },
   "source": [
    "## Building a Small Convnet Model\n",
    "\n",
    "The images that will go into our convnet are **32 x 32** color images. You are free to resize the images for faster training time.\n",
    "\n",
    "Here, we designed the architecture such that it contains 2 {convolution + relu + maxpooling} modules. Our convolutions operate on **3x3** windows and our maxpooling layers operate on **2x2** windows. Our first convolution extracts **16** filters and the second extracts **32** filters.\n",
    "\n",
    "On top of the convolution layers, we flatten the 2-dim matrix into 1-dim vector and feed them into 2 fully connected layers. The first fully connected layer has 128 hidden units and the last one has the same number of outputs as our classes (10).\n",
    "\n",
    "NOTE: This is a basic configuration for image classification. You are free to modify the model to improve the accuracy while watching for overfitting/underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "NFYlZE4DTWtO",
    "outputId": "19510c32-0289-40f8-bcae-af9e32457c44"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "# Here we specify the input shape of our data \n",
    "# This should match the size of images ('image_size') along with the number of channels (3)\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 10\n",
    "\n",
    "# Initialising the model\n",
    "model = Sequential()\n",
    "\n",
    "# First convolution extracts 16 filters that are of kernel size 3x3 \n",
    "model.add(Conv2D(_____, (_____), \n",
    "                 padding='same', \n",
    "                 strides=2, \n",
    "                 input_shape=input_shape,\n",
    "                 activation='relu'))\n",
    "\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "model.add(MaxPooling2D(pool_size=(_____)))\n",
    "\n",
    "# Second convolution extracts 32 filters that are of kernel size 3x3 \n",
    "model.add(Conv2D(_____, (3,3), \n",
    "                 padding='same', \n",
    "                 strides=2,\n",
    "                 activation='_____'))\n",
    "\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten 2-dim matrix to 1-d vector so we can pass them through the fully connected layer (dense layer)\n",
    "model.add(Flatten())\n",
    "\n",
    "# Create a fully connected layer with ReLU activation and 128 hidden units\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Create an output layer with the number of classes and activate using softmax\n",
    "model.add(Dense(num_classes, activation='_____'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av-Mk7KZKD7Q"
   },
   "source": [
    "Let's summarise the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "eEwSI4-FKDg4",
    "outputId": "557586ae-49cc-4358-fc0b-4c8db13f3e4b"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jFT6kbPZ_Wi"
   },
   "source": [
    "Next, we will configure the specifications for model training.\n",
    "\n",
    "We train our model with `categorical_crossentropy` loss, because this is a multi-class problem. We will use the `adam` optimizer with a learning rate of `0.001`. During training, we want to monitor `accuracy` of the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Xmx5IvQZ4oK"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.001),\n",
    "              metrics=['_____'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0rPDjqYaEmq"
   },
   "source": [
    "## Model Training \n",
    "\n",
    "For educational purposes. Let's train on 500 images, for 10 epochs, and validate against all 50 validation images.\n",
    "\n",
    "Note: This may take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1108
    },
    "colab_type": "code",
    "id": "bzU1gNrcTPX3",
    "outputId": "440033fe-bea4-4189-b0b4-bdbac51c9839"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator, # train generator has 50,000 train images but we are not using all of them\n",
    "        steps_per_epoch=50, # training 500 images = 50 steps x 10 images per batch\n",
    "        epochs=30,\n",
    "        validation_data=val_generator, # validation generator has 5,000 validation images\n",
    "        validation_steps=5 # validating on 50 images = 5 steps x 10 images per batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFVkjJnBfCe_"
   },
   "source": [
    "## Evaluating Accuracy and Loss of the Model\n",
    "\n",
    "With a trained model, we can evaluate the model performance against the truth labels of our validation set. Note that we are validating against 50 sets i.e. 500 images, instead of the 50 images we validated in each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ywpKyHBZSF02",
    "outputId": "95d7ebf6-ebea-498f-df3d-3cab073f7c22"
   },
   "outputs": [],
   "source": [
    "# Validating against 50 steps, 500 images in total\n",
    "scores = model.evaluate_generator(val_generator, steps=50, verbose=1)\n",
    "print('Val loss:', scores[0])\n",
    "print('Val accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PLj8XGNQ2qd3"
   },
   "source": [
    "## Model Prediction against Test Set\n",
    "\n",
    "Using the trained model, we now predict the classes in the **test set**. The test set contains images from all classes, all placed in a single folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tEKJnGpNA0E1",
    "outputId": "1f759f55-37c2-4f01-d571-b7739df58110"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 500 steps x 10 images per batch = 5,000 images\n",
    "preds = model.predict_generator(test_generator, steps=500, verbose=1)\n",
    "\n",
    "# Get labels from truth\n",
    "# {0: 'airplane',\n",
    "#  1: 'automobile',\n",
    "#  ...}\n",
    "label_dict = dict((v,k) for k,v in (train_generator.class_indices).items())\n",
    "\n",
    "# Get a list of predictions ['horse', 'airplane', ...]\n",
    "predicted_class_indices = np.array([np.argmax(x) for x in preds])\n",
    "predictions = [label_dict[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRhqwDeQ7C77"
   },
   "outputs": [],
   "source": [
    "## CHANGE HERE\n",
    "TEAM_ID = \"_____\"\n",
    "SUBMISSION_TYPE = \"cifar10_test_set\"\n",
    "\n",
    "# Preparing results into dataframe\n",
    "results=pd.DataFrame({\"filename\":test_generator.filenames,\n",
    "                      \"prediction\":predictions})\n",
    "\n",
    "# Output a CSV (optional)\n",
    "# results.to_csv('results.csv', index = None)\n",
    "\n",
    "# Peparing submission payload\n",
    "submission = {\n",
    "    \"team_id\": TEAM_ID,\n",
    "    \"submission_type\": SUBMISSION_TYPE\n",
    "}\n",
    "submission['predictions'] = json.loads(results.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Rr6oE8JNwBJX",
    "outputId": "64752ad3-4cba-447e-f8ee-9de71418e5ac"
   },
   "outputs": [],
   "source": [
    "# Take a look at our submission\n",
    "json.dumps(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "K3uBAz8qB-tg",
    "outputId": "ce9b5daf-7113-472e-969f-165b33573c4b"
   },
   "outputs": [],
   "source": [
    "## Function for submission\n",
    "def submit_result(submission):\n",
    "    import requests\n",
    "    headers = {'content-type' : 'application/json'}\n",
    "    url = \"https://yfpki7bqa9.execute-api.us-east-1.amazonaws.com/default/submit\"\n",
    "    res = requests.post(url, data=json.dumps(submission), headers=headers)\n",
    "    return res.json()\n",
    "\n",
    "## Calling the function to submit\n",
    "submit_result(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2_Image Classification - CIFAR10 (instructor)",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Putting it all together - Model Evaluation against Validation Set\n",
    "\n",
    "In this notebook we will use our train model to do some prediction on our validation set. In the competition, we will evaluate your model against unseen test set!\n",
    "\n",
    "Here are the steps to evaluate your model:\n",
    "1. Download the necessary Python module (AiCampEval) to prepare for submission \n",
    "2. Load your trained model\n",
    "3. Write a function that takes in a list of numpy array images and returns a list of predictions\n",
    "4. Pass the function into the evaluation model, enter your `team_id` and `submission_type`, and wait for your result\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Install the Evaluation Module\n",
    "\n",
    "The following command downloads and installs the evaluation module required to do your submission. Note: If you fail to load the module `AiCampEval` after running `pip install`, please try restarting your kernel and run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall --user --no-warn-script-location -q https://ai-camp.s3-us-west-2.amazonaws.com/AiCampEval-1.7-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AiCampEval import eval_submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "Let's begin by loading our best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path = 'saved_model.hdf5'\n",
    "model = load_model( model_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in `train_generator` to get the class_indices as we will be using it in our function `evaluate_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = 'data/trainset_11classes_0_00000'\n",
    "train_folder = os.path.join(base_dir, 'train')\n",
    "\n",
    "# Batch size\n",
    "bs = 32\n",
    "\n",
    "# All images will be resized to this value\n",
    "image_size = (299, 299)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   brightness_range= [0.5,1.5],\n",
    "                                   horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory= train_folder, # This is the source directory for training images \n",
    "    target_size=image_size, # All images will be resized to value set in image_size\n",
    "    batch_size=bs,\n",
    "    class_mode='categorical')\n",
    "\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction against Test Set\n",
    "\n",
    "Using the trained model, we now predict the classes in a **test set**. The test set contains images from all classes, all placed in a single folder. In this toy example, we will be using the `val` folder as a test set, so expect to see the same score as what we got for validation above.\n",
    "\n",
    "You will be required to create a function that accepts a list of numpy array images as input and outputs a list of prediction strings corresponding to each image in the input list.\n",
    "\n",
    "`predictions` should be a list of string: [ 'ChildPose', 'KoreanHeart', 'ChildPose', 'KungfuSalute', ...]. It's length should be the length of list_of_np_arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "'''\n",
    "This is a helper function to preprocess the input before sending it through my network. \n",
    "It performs the following steps:\n",
    "1. Resizes each image to (224,224,3), which are the image dimensions my model was trained on.\n",
    "2. Normalizes the range of each pixel's value from [0-255] to [0-1].\n",
    "3. Reshapes each array such that it has a batch dimension: from  (224,224,3) -> (1,224,224,3), \n",
    "because my model.predict function expects a batch dimension.\n",
    "\n",
    "Implement your own preprocessing function according to your model's needs.\n",
    "''' \n",
    "def preprocess_arrays(list_of_np_arrays):\n",
    "    target_size = image_size\n",
    "    pil_images = [ Image.fromarray(arr.astype('uint8'), 'RGB') for arr in list_of_np_arrays ]\n",
    "    resized_pil_images = [img.resize( target_size, Image.NEAREST ) for img in pil_images]\n",
    "    resized_images = [np.array( img ) for img in resized_pil_images]\n",
    "    preprocessed_images = [np.expand_dims(x, axis=0) / 255. for x in resized_images]\n",
    "    return preprocessed_images\n",
    "\n",
    "'''\n",
    "This function accepts a list of numpy array images as input and outputs a list of prediction strings \n",
    "corresponding to each image in the input list.\n",
    "IMPORTANT: you have to implement this function.\n",
    "''' \n",
    "def evaluate_images(list_of_np_arrays):\n",
    "    # Swap the key and value in the class_indices\n",
    "    label_dict = dict((v,k) for k,v in (train_generator.class_indices).items())\n",
    "    # Run through the list_of_np_arrays to perform any preprocessing you need\n",
    "    preprocessed_imgs = preprocess_arrays( list_of_np_arrays )\n",
    "    # Get a list of softmax_vectors by passing in the preprocessed_imgs to model.predict()\n",
    "    softmax_vectors = [ model.predict( x )[0] for x in preprocessed_imgs ]\n",
    "    # Get the predicted_class_indices by running each of the softmax_vectors through np.argmax()\n",
    "    predicted_class_indices = [ np.argmax( x ) for x in softmax_vectors ]\n",
    "    # Convert the list of class_indices to a list of predictions (in str)\n",
    "    # predictions is a list of labels: ['KoreanHeart', 'KoreanHeart','ChairPose',.......]\n",
    "    predictions = [ label_dict[k] for k in predicted_class_indices ]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "The `eval_submit` function takes in 3 parameters - your function, TEAM_ID and SUBMISSION_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHANGE HERE\n",
    "TEAM_ID = \"CHANGE_HERE\"\n",
    "SUBMISSION_TYPE = \"trainset_11classes_0_val\"\n",
    "\n",
    "eval_submit(evaluate_images, SUBMISSION_TYPE, TEAM_ID )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
